# advance-reasearch
Project Overview
This project demonstrates how to fine-tune a pre-trained BERT model for binary sentiment classification using the Yelp Polarity dataset. The model is trained to classify customer reviews as either positive or negative.

Model
Model used: bert-base-uncased

Task: Text classification (binary sentiment)

Framework: Hugging Face Transformers

Tokenizer: BERT WordPiece tokenizer

Dataset
Source: Hugging Face Datasets (yelp_polarity)

Classes: Positive (1), Negative (0)

Used Samples:

10,000 reviews for training

2,000 reviews for validation
